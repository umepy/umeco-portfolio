---
title: "【論文読み】Llama1からLlama2で何が進化したのか？"
date: "2023-07-14T12:00:00+09:00"
tags: ["備忘録", "AI"]
header_image: "/blog/girl_study.jpg"
---

# 今更聞けない大規模言語モデル【Llama2】

## 概要

Llama2とは7/26日にMetaが公開した大規模事前学習済みモデルです。ちなみに読み方はラマです(始めて見たときはエルラマ!?って思ってました)。
Llama2は公開されているモデルの中では英語において現状最高の性能を誇っていると思われます。
Llama1の発表から半年を経たずにアップデートされたLlama2ですが、何が変わったのか論文を読んでまとめました。

## 大規模言語モデルとは？

大規模言語モデル(LLM: Large Language Model)とは、一言で言うと「大量のテキストデータを学習させた言語モデル」のことで、言語モデルとは文章の次の単語を予測するモデルのことです。次の単語を予測する、という動作を繰り返すことで長い文章を生成することができます。

最近LLMという言葉をよく聞くようになりましたが、個人的には大きく話題になったのは2019年のGPT-2の発表からだと思っています。この時はOpenAIはGPT-2のモデルを公開しなかったのですが、その理由が「文章生成の精度が高すぎたため悪用される可能性がある」ということでした。

参考: [当時の記事](https://www.gizmodo.jp/2019/02/elon_musk_backed_text_generating_ai.html)

まだこの頃のLLMは単に次の単語を予測するだけのモデルで、用途としては文章執筆程度だと思われていて応用は限られていました。しかし、2020年に入ってからはGPT-3の発表や、GPT-3を使った様々な応用が話題になり、LLMの応用範囲が広がってきました。 ポイントとしてはスケーリング則と呼ばれる、モデルのパラメータ数/データ量/計算量を増やすことでモデルの精度が急速に向上するということが分かってきたことです。そのため、より大規模なデータセット、より大規模なモデル、より大規模な計算資源を費やすことで、より高い精度のモデルが作れるようになってきました。

そして、ここからより"賢いAI"となるために様々な手法が提案されています。Instruct tuningやRLHF(Reinforcement Learning from Human Feedback)という手法で、Instruct tuningでは指示の内容とその返答が正解データとして与えられたデータセットを使って教師あり学習をします。論文としては[FLAN](https://arxiv.org/abs/2109.01652)などで提案されました。また、これだけだとデータの多様性が少なく精度が出ないことが多く、強化学習を使ったRLHFという手法も提案されています。モデルに同じ質問に対し複数の回答をしてもらい、その回答に対して点数を付け、いい回答をするように学習させるという手法です。詳しくは[InstructGPTの論文](https://arxiv.org/abs/2203.02155)に説明があります。これらの手法によって学習されたモデルは10倍以上のパラメータ数のモデルと同等以上の性能を示すなどの報告がされています。直観的には、また、定性的にはこれらのtuningを実施することにより、人間らしい回答をするようになったと感じます(人間が好むような回答をするようにtuningしたので当たり前ではありますが..)。

このようにして次の単語しか生成できないモデルからより高度な応用ができるモデルへと進化してき、その応用の広さから大きな注目を集めています。
